{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Coach as a Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coach can be used as a library directly from python. As described in previous notebooks, Coach uses the presets mechanism to define the experiments. A preset is essentially a python module which instantiates a `GraphManager` object. The graph manager is a container that holds the agents and the environments, and has some additional parameters for running the experiment, such as visualization parameters. The graph manager acts as the scheduler which orchestrates the experiment.\n",
    "Running Coach directly from python is done through a `CoachInterface` object, which uses the same arguments as the command line invocation but allowes for more flexibility and additional control of the training/inference process.\n",
    "\n",
    "Let's start with some examples.\n",
    "\n",
    "Creating a very simple graph containing a single Clipped PPO agent running with the CartPole-v0 Gym environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding module path to sys path if not there, so rl_coach submodules can be imported\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from rl_coach.coach import CoachInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach = CoachInterface(preset='CartPole_ClippedPPO',\n",
    "                       custom_parameter='heatup_steps=EnvironmentSteps(5);improve_steps=TrainingSteps(3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the graph according to the given schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running each phase manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph manager (which was instantiated in the preset) can be accessed from the `CoachInterface` object. The graph manager simplifies the scheduling process by encapsulating the calls to each of the training phases. Sometimes, it can be beneficial to have a more fine grained control over the scheduling process. This can be easily done by calling the individual phase functions directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_coach.core_types import EnvironmentSteps\n",
    "\n",
    "coach.graph_manager.heatup(EnvironmentSteps(100))\n",
    "for _ in range(10):\n",
    "    coach.graph_manager.train_and_act(EnvironmentSteps(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional functionality\n",
    "\n",
    "`CoachInterface` allows for easy access to functionalities such as multi-threading and saving checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach = CoachInterface(preset='CartPole_ClippedPPO', num_workers=2, checkpoint_save_secs=10)\n",
    "coach.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent functionality\n",
    "\n",
    "When using `CoachInterface` (single agent with one level of hierarchy) it's also possible to easily use the `Agent` object functionality, such as logging signals and applying the policy the agent has learned on a given state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_coach.environments.gym_environment import GymEnvironment,  GymVectorEnvironment\n",
    "from rl_coach.base_parameters import VisualizationParameters\n",
    "from rl_coach.core_types import EnvironmentSteps\n",
    "\n",
    "coach = CoachInterface(preset='CartPole_ClippedPPO')\n",
    "\n",
    "# training\n",
    "for it in range(10):\n",
    "    coach.graph_manager.train_and_act(EnvironmentSteps(100))\n",
    "    coach.graph_manager.log_signal('iteration', it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "env_params = GymVectorEnvironment(level='CartPole-v0')\n",
    "env = GymEnvironment(**env_params.__dict__, visualization_parameters=VisualizationParameters())\n",
    "\n",
    "for it in range(10):\n",
    "    action_info = coach.graph_manager.get_agent().choose_action(env.state)\n",
    "    print(\"State:{}, Action:{}\".format(env.state,action_info.action))\n",
    "    env.step(action_info.action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
