{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a very simple graph containing a single clipped ppo agent running with the CartPole-v0 Gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_coach.agents.clipped_ppo_agent import ClippedPPOAgentParameters\n",
    "from rl_coach.environments.gym_environment import GymVectorEnvironment\n",
    "from rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManager\n",
    "from rl_coach.graph_managers.graph_manager import SimpleSchedule\n",
    "\n",
    "graph_manager = BasicRLGraphManager(\n",
    "    agent_params=ClippedPPOAgentParameters(),\n",
    "    env_params=GymVectorEnvironment(level='CartPole-v0'),\n",
    "    schedule_params=SimpleSchedule()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the graph according to the given schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_manager.improve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30;46mCreating graph - name: BasicRLGraphManager\u001b[0m\n",
      "\u001b[30;46mCreating agent - name: agent\u001b[0m\n",
      "\u001b[30;46msimple_rl_graph: Starting heatup\u001b[0m\n",
      "\u001b[95mHeatup\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m1 \u001b[94mTotal reward: \u001b[0m21.0 \u001b[94mSteps: \u001b[0m21 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mHeatup\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m2 \u001b[94mTotal reward: \u001b[0m27.0 \u001b[94mSteps: \u001b[0m48 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mHeatup\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m3 \u001b[94mTotal reward: \u001b[0m46.0 \u001b[94mSteps: \u001b[0m94 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mHeatup\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m4 \u001b[94mTotal reward: \u001b[0m34.0 \u001b[94mSteps: \u001b[0m128 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mTraining\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m5 \u001b[94mTotal reward: \u001b[0m36.0 \u001b[94mSteps: \u001b[0m164 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mTraining\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m6 \u001b[94mTotal reward: \u001b[0m19.0 \u001b[94mSteps: \u001b[0m183 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mTraining\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m7 \u001b[94mTotal reward: \u001b[0m22.0 \u001b[94mSteps: \u001b[0m205 \u001b[94mTraining iteration: \u001b[0m0 \n",
      "\u001b[95mTraining\u001b[0m - \u001b[94mName: \u001b[0mmain_level/agent \u001b[94mEpisode: \u001b[0m8 \u001b[94mTotal reward: \u001b[0m11.0 \u001b[94mSteps: \u001b[0m216 \u001b[94mTraining iteration: \u001b[0m0 \n"
     ]
    }
   ],
   "source": [
    "from rl_coach.core_types import EnvironmentSteps\n",
    "\n",
    "graph_manager = BasicRLGraphManager(\n",
    "    agent_params=ClippedPPOAgentParameters(),\n",
    "    env_params=GymVectorEnvironment(level='CartPole-v0'),\n",
    "    schedule_params=SimpleSchedule()\n",
    ")\n",
    "\n",
    "graph_manager.heatup(EnvironmentSteps(100))\n",
    "graph_manager.train_and_act(EnvironmentSteps(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule\n",
    "schedule_params = ScheduleParameters()\n",
    "schedule_params.improve_steps = TrainingSteps(10000000)\n",
    "schedule_params.steps_between_evaluation_periods = EnvironmentSteps(2048)\n",
    "schedule_params.evaluation_steps = EnvironmentEpisodes(5)\n",
    "schedule_params.heatup_steps = EnvironmentSteps(0)\n",
    "\n",
    "# agent parameters\n",
    "agent_params = ClippedPPOAgentParameters()\n",
    "agent_params.algorithm.discount = 1.0\n",
    "\n",
    "graph_manager = BasicRLGraphManager(\n",
    "    agent_params=agent_params,\n",
    "    env_params=GymVectorEnvironment(level='CartPole-v0'),\n",
    "    schedule_params=schedule_params\n",
    ")\n",
    "\n",
    "graph_manager.improve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
